{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3a2f3b",
   "metadata": {},
   "source": [
    "## Challenge TelecomX-2-ML ‚Äì An√°lisis Predictivo de Churn\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "En esta segunda etapa del Challenge de Data Science de Alura, el enfoque se centra en el **modelado predictivo** para anticipar la evasi√≥n de clientes (Churn) en TelecomX.\n",
    "Luego de completar el proceso de **ETL y An√°lisis Exploratorio (EDA)**, el objetivo ahora es construir, evaluar y optimizar modelos de Machine Learning que permitan:\n",
    "\n",
    "* Predecir qu√© clientes tienen mayor probabilidad de abandonar el servicio.\n",
    "* Identificar las variables m√°s influyentes en la decisi√≥n de churn.\n",
    "* Proporcionar recomendaciones estrat√©gicas basadas en evidencia predictiva.\n",
    "\n",
    "\n",
    "Flujo de implementaci√≥n:\n",
    "\n",
    "1. Feature Engineering\n",
    "2. Preprocesamiento\n",
    "3. Train/Test SplitPipeline\n",
    "4. Cross-Validation (en Train)\n",
    "5. Comparaci√≥n de modelos\n",
    "6. Optimizaci√≥n\n",
    "7. Entrenamiento final\n",
    "8. Evaluaci√≥n en Test\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a27c55",
   "metadata": {},
   "source": [
    "## Implementaci√≥n del Modelado Predictivo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e4963",
   "metadata": {},
   "source": [
    "### Importaci√≥n de librer√≠as y configuraci√≥n del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f42eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bibliotecas importadas y entorno configurado correctamente\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# CONFIGURACI√ìN GLOBAL\n",
    "# ==============================\n",
    "\n",
    "# Ignorar warnings irrelevantes\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# BIBLIOTECAS PARA MANEJO DE DATOS\n",
    "# ==============================\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ==============================\n",
    "# BIBLIOTECAS PARA PREPROCESAMIENTO - ML\n",
    "# ==============================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# ==============================\n",
    "# BIBLIOTECAS PARA VISUALIZACI√ìN\n",
    "# ==============================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==============================\n",
    "# CONFIGURACI√ìN DE VISUALIZACIONES\n",
    "# ==============================\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Si trabajas en Jupyter, puedes activar esto:\n",
    "# %matplotlib inline\n",
    "\n",
    "# ==============================\n",
    "# CONFIGURACI√ìN DE PANDAS\n",
    "# ==============================\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# ==============================\n",
    "# PALETA DE COLORES PERSONALIZADA\n",
    "# ==============================\n",
    "\n",
    "color_no_churn = '#2C3E50'  # Azul oscuro elegante\n",
    "color_churn = '#E74C3C'     # Rojo elegante\n",
    "\n",
    "color_palette = [\n",
    "  '#F8F9FA', # Fondo Limpio (Ghost White)\n",
    "  '#E9ECEF', # Bordes/Secciones (Slate Gray)\n",
    "  '#22577A', # T√≠tulos/Estructura (Dark Imperial Blue)\n",
    "  '#38A3A5', # Procesos activos (Cadet Blue)\n",
    "  '#57CC99', # √âxito/Validaci√≥n (Emerald)\n",
    "  '#80ED99'  # Acentos ligeros (Light Green)\n",
    "]\n",
    "\n",
    "sns.set_palette(color_palette)\n",
    "\n",
    "# ==============================\n",
    "# CREAR CARPETA PARA IM√ÅGENES\n",
    "# ==============================\n",
    "\n",
    "os.makedirs('imgs', exist_ok=True)\n",
    "\n",
    "print('‚úÖ Bibliotecas importadas y entorno configurado correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c55c3f",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "\n",
    "Previo an√°lisis con dataset generado en la 1ra etapa y al no encontrar mayores inconsistencias, se utiliza el dataset proprocionado por Alura One \"dataset_tratado.csv\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987d384b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>ChargesDaily</th>\n",
       "      <th>ChargesMonthly</th>\n",
       "      <th>ChargesTotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5611</th>\n",
       "      <td>7901-TBKJX</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>56</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>3.37</td>\n",
       "      <td>101.05</td>\n",
       "      <td>5594.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>5176-LDKUH</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>48</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>2.51</td>\n",
       "      <td>75.15</td>\n",
       "      <td>3772.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>5668-MEISB</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>3.54</td>\n",
       "      <td>106.10</td>\n",
       "      <td>7657.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CustomerID Churn  Gender SeniorCitizen Partner Dependents  Tenure  \\\n",
       "5611  7901-TBKJX    No    Male           Yes      No         No      56   \n",
       "3668  5176-LDKUH    No  Female            No      No         No      48   \n",
       "4020  5668-MEISB    No  Female            No     Yes        Yes      72   \n",
       "\n",
       "     PhoneService MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
       "5611          Yes           Yes     Fiber optic             No           No   \n",
       "3668          Yes            No     Fiber optic             No          Yes   \n",
       "4020          Yes           Yes     Fiber optic            Yes          Yes   \n",
       "\n",
       "     DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "5611              Yes          No         Yes             Yes  Month-to-month   \n",
       "3668               No          No          No              No        One year   \n",
       "4020              Yes         Yes         Yes              No        Two year   \n",
       "\n",
       "     PaperlessBilling            PaymentMethod  ChargesDaily  ChargesMonthly  \\\n",
       "5611              Yes         Electronic check          3.37          101.05   \n",
       "3668               No         Electronic check          2.51           75.15   \n",
       "4020               No  Credit card (automatic)          3.54          106.10   \n",
       "\n",
       "      ChargesTotal  \n",
       "5611       5594.00  \n",
       "3668       3772.65  \n",
       "4020       7657.40  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/LenninTemoche/Challenge-TelecomX-2-Alura-One-DS/refs/heads/main/datos_tratados.csv\"\n",
    "\n",
    "df = pd.read_csv(url, sep=\",\")\n",
    "\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce933ce2",
   "metadata": {},
   "source": [
    "## 1. Limpieza de Datos\n",
    "\n",
    "En esta etapa se garantiza la calidad del dataset antes del modelado.\n",
    "\n",
    "Se realizaron las siguientes acciones:\n",
    "\n",
    "- Estandarizaci√≥n de categor√≠as inconsistentes.\n",
    "- Eliminaci√≥n de variables sin valor predictivo.\n",
    "- Verificaci√≥n final de valores nulos.\n",
    "- Eliminaci√≥n de registros duplicados (si existieran).\n",
    "\n",
    "Este paso es fundamental para evitar ruido, sesgos y errores en el entrenamiento de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80c55e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando limpieza de datos...\n",
      "\n",
      "üìå DIAGN√ìSTICO INICIAL\n",
      "Filas iniciales: 7043\n",
      "Columnas iniciales: 22\n",
      "Nulos totales iniciales: 0\n",
      "Duplicados iniciales (con ID): 0\n",
      "\n",
      "üîÑ Estandarizando categor√≠as...\n",
      "\n",
      "Columna: OnlineSecurity\n",
      "Valores √∫nicos antes:\n",
      "OnlineSecurity\n",
      "No     5024\n",
      "Yes    2019\n",
      "Name: count, dtype: int64\n",
      "Valores √∫nicos despu√©s:\n",
      "OnlineSecurity\n",
      "No     5024\n",
      "Yes    2019\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Columna: OnlineBackup\n",
      "Valores √∫nicos antes:\n",
      "OnlineBackup\n",
      "No     4614\n",
      "Yes    2429\n",
      "Name: count, dtype: int64\n",
      "Valores √∫nicos despu√©s:\n",
      "OnlineBackup\n",
      "No     4614\n",
      "Yes    2429\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Columna: DeviceProtection\n",
      "Valores √∫nicos antes:\n",
      "DeviceProtection\n",
      "No     4621\n",
      "Yes    2422\n",
      "Name: count, dtype: int64\n",
      "Valores √∫nicos despu√©s:\n",
      "DeviceProtection\n",
      "No     4621\n",
      "Yes    2422\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Columna: TechSupport\n",
      "Valores √∫nicos antes:\n",
      "TechSupport\n",
      "No     4999\n",
      "Yes    2044\n",
      "Name: count, dtype: int64\n",
      "Valores √∫nicos despu√©s:\n",
      "TechSupport\n",
      "No     4999\n",
      "Yes    2044\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Columna: StreamingTV\n",
      "Valores √∫nicos antes:\n",
      "StreamingTV\n",
      "No     4336\n",
      "Yes    2707\n",
      "Name: count, dtype: int64\n",
      "Valores √∫nicos despu√©s:\n",
      "StreamingTV\n",
      "No     4336\n",
      "Yes    2707\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Columna: StreamingMovies\n",
      "Valores √∫nicos antes:\n",
      "StreamingMovies\n",
      "No     4311\n",
      "Yes    2732\n",
      "Name: count, dtype: int64\n",
      "Valores √∫nicos despu√©s:\n",
      "StreamingMovies\n",
      "No     4311\n",
      "Yes    2732\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categor√≠as estandarizadas correctamente.\n",
      "\n",
      "üóë Validando eliminaci√≥n de ID...\n",
      "Columnas antes de eliminar ID: 22\n",
      "Se elimin√≥ columna 'CustomerID'\n",
      "Columnas despu√©s de eliminar ID: 21\n",
      "Duplicados despu√©s de eliminar ID: 22\n",
      "\n",
      "üßπ Eliminando duplicados (si existen)...\n",
      "Se eliminaron 22 registros duplicados.\n",
      "Filas actuales: 7021\n",
      "\n",
      "üìå VERIFICACI√ìN FINAL\n",
      "No hay valores nulos en el dataset.\n",
      "Nulos totales finales: 0\n",
      "\n",
      "‚úÖ Limpieza de datos finalizada correctamente.\n",
      "Shape final del dataset: (7021, 21)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1Ô∏è‚É£ LIMPIEZA DE DATOS (con validaciones antes y despu√©s)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Iniciando limpieza de datos...\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üîé 1.0 Diagn√≥stico inicial general\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüìå DIAGN√ìSTICO INICIAL\")\n",
    "\n",
    "print(f\"Filas iniciales: {df.shape[0]}\")\n",
    "print(f\"Columnas iniciales: {df.shape[1]}\")\n",
    "\n",
    "# ---- Nulos iniciales ----\n",
    "nulos_iniciales = df.isnull().sum().sum()\n",
    "print(f\"Nulos totales iniciales: {nulos_iniciales}\")\n",
    "\n",
    "# ---- Duplicados iniciales (con ID si existe) ----\n",
    "duplicados_iniciales = df.duplicated().sum()\n",
    "print(f\"Duplicados iniciales (con ID): {duplicados_iniciales}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1.1 Estandarizaci√≥n de categor√≠as\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüîÑ Estandarizando categor√≠as...\")\n",
    "\n",
    "cols_to_fix = [\n",
    "    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "    'TechSupport', 'StreamingTV', 'StreamingMovies'\n",
    "]\n",
    "\n",
    "for col in cols_to_fix:\n",
    "    if col in df.columns:\n",
    "        antes = df[col].value_counts(dropna=False)\n",
    "        df[col] = df[col].replace({'No internet service': 'No'})\n",
    "        despues = df[col].value_counts(dropna=False)\n",
    "\n",
    "        print(f\"\\nColumna: {col}\")\n",
    "        print(\"Valores √∫nicos antes:\")\n",
    "        print(antes)\n",
    "        print(\"Valores √∫nicos despu√©s:\")\n",
    "        print(despues)\n",
    "\n",
    "print(\"\\nCategor√≠as estandarizadas correctamente.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1.2 Eliminaci√≥n de variable identificadora\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüóë Validando eliminaci√≥n de ID...\")\n",
    "\n",
    "print(f\"Columnas antes de eliminar ID: {df.shape[1]}\")\n",
    "\n",
    "if 'CustomerID' in df.columns:\n",
    "    df = df.drop(columns=['CustomerID'])\n",
    "    print(\"Se elimin√≥ columna 'CustomerID'\")\n",
    "elif 'customerID' in df.columns:\n",
    "    df = df.drop(columns=['customerID'])\n",
    "    print(\"Se elimin√≥ columna 'customerID'\")\n",
    "else:\n",
    "    print(\"No se encontr√≥ columna identificadora.\")\n",
    "\n",
    "print(f\"Columnas despu√©s de eliminar ID: {df.shape[1]}\")\n",
    "\n",
    "# ---- Validar duplicados despu√©s de quitar ID ----\n",
    "duplicados_sin_id = df.duplicated().sum()\n",
    "print(f\"Duplicados despu√©s de eliminar ID: {duplicados_sin_id}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1.3 Eliminaci√≥n de duplicados\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüßπ Eliminando duplicados (si existen)...\")\n",
    "\n",
    "filas_antes = df.shape[0]\n",
    "\n",
    "if duplicados_sin_id > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    filas_despues = df.shape[0]\n",
    "    print(f\"Se eliminaron {filas_antes - filas_despues} registros duplicados.\")\n",
    "else:\n",
    "    print(\"No se encontraron registros duplicados.\")\n",
    "\n",
    "print(f\"Filas actuales: {df.shape[0]}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1.4 Verificaci√≥n final de nulos\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüìå VERIFICACI√ìN FINAL\")\n",
    "\n",
    "nulos_finales = df.isnull().sum().sum()\n",
    "\n",
    "reporte_final = pd.DataFrame({\n",
    "    'Nulos': df.isnull().sum(),\n",
    "    'Porcentaje (%)': (df.isnull().sum() / len(df)) * 100\n",
    "}).sort_values(by='Nulos', ascending=False)\n",
    "\n",
    "if nulos_finales > 0:\n",
    "    print(\"Columnas con nulos:\")\n",
    "    print(reporte_final[reporte_final['Nulos'] > 0])\n",
    "else:\n",
    "    print(\"No hay valores nulos en el dataset.\")\n",
    "\n",
    "print(f\"Nulos totales finales: {nulos_finales}\")\n",
    "\n",
    "print(\"\\n‚úÖ Limpieza de datos finalizada correctamente.\")\n",
    "print(f\"Shape final del dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b73042",
   "metadata": {},
   "source": [
    "\n",
    "### 1 Ingenier√≠a de Caracter√≠sticas (Feature Engineering)\n",
    "\n",
    "En esta fase se optimizan y crean variables para mejorar la capacidad predictiva del modelo.\n",
    "\n",
    "* **Creaci√≥n de `num_services`**: Variable que cuantifica la intensidad de uso del cliente. Un mayor n√∫mero de servicios puede reflejar mayor fidelizaci√≥n o mayor complejidad de abandono.\n",
    "* **Variables derivadas**: Posible creaci√≥n de ratios como gasto promedio por servicio.\n",
    "* **Eliminaci√≥n de variables irrelevantes o redundantes**:\n",
    "\n",
    "  * `CustomerID` (identificador sin valor predictivo).\n",
    "  * An√°lisis de variables altamente correlacionadas que puedan generar multicolinealidad.\n",
    "* **An√°lisis de importancia preliminar** para validar aporte de nuevas variables.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c71a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Nueva columna creada: 'num_services' (Rango: 1 - 9 servicios)\n"
     ]
    }
   ],
   "source": [
    "# Creaci√≥n de la variable num_services\n",
    "# 1. Definimos las columnas que representan servicios\n",
    "service_cols = [\n",
    "    'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
    "    'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies'\n",
    "]\n",
    "\n",
    "# 2. Funci√≥n para contar los servicios activos de cada cliente\n",
    "def count_services(row):\n",
    "    count = 0\n",
    "    # InternetService: Si es 'DSL' o 'Fiber optic' cuenta como 1 (si es 'No', es 0)\n",
    "    if row['InternetService'] != 'No':\n",
    "        count += 1\n",
    "    \n",
    "    # Para el resto, sumamos 1 si el valor es 'Yes'\n",
    "    for col in service_cols:\n",
    "        if col != 'InternetService' and row[col] == 'Yes':\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# Aplicamos la funci√≥n para crear la nueva columna\n",
    "df['num_services'] = df.apply(count_services, axis=1)\n",
    "\n",
    "print(f\"‚úÖ Nueva columna creada: 'num_services' (Rango: {df['num_services'].min()} - {df['num_services'].max()} servicios)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d08593",
   "metadata": {},
   "source": [
    "#### Creaci√≥n de la variable `num_services`\n",
    "\n",
    "Se construy√≥ una nueva variable que cuantifica la cantidad de servicios activos contratados por cada cliente.\n",
    "\n",
    "La l√≥gica aplicada fue:\n",
    "\n",
    "- Si el cliente posee Internet (DSL o Fiber optic), se considera 1 servicio.\n",
    "- Se suma 1 por cada servicio adicional activo (`Yes`).\n",
    "- Servicios sin contrataci√≥n o con valor \"No internet service\" no se contabilizan.\n",
    "\n",
    "Esta variable busca capturar la intensidad de uso del cliente, ya que un mayor n√∫mero de servicios puede estar asociado con mayor fidelizaci√≥n o mayor complejidad de abandono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f59bfa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['CustomerID'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCustomerID\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KEILY\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KEILY\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KEILY\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4852\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4850\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4851\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4852\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4853\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KEILY\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['CustomerID'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['CustomerID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58505ef",
   "metadata": {},
   "source": [
    "### Eliminaci√≥n de variable identificadora\n",
    "\n",
    "Se elimin√≥ la columna `CustomerID` debido a que es un identificador √∫nico sin valor predictivo.\n",
    "\n",
    "Mantenerla podr√≠a introducir ruido o sobreajuste en modelos basados en √°rboles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cedbcbf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2 Preprocesamiento de Datos (Data Preprocessing)\n",
    "\n",
    "Preparaci√≥n t√©cnica de los datos para su uso en modelos de Machine Learning.\n",
    "\n",
    "* **Codificaci√≥n de Variables Categ√≥ricas**:\n",
    "\n",
    "  * One-Hot Encoding para variables nominales (ej. `PaymentMethod`).\n",
    "  * Label Encoding para la variable objetivo (`Churn`: 0 = No, 1 = S√≠).\n",
    "\n",
    "* **Escalado de Variables Num√©ricas**:\n",
    "\n",
    "  * Estandarizaci√≥n (StandardScaler) o Normalizaci√≥n (MinMaxScaler).\n",
    "  * Aplicado a variables como:\n",
    "\n",
    "    * `Tenure`\n",
    "    * `ChargesMonthly`\n",
    "    * `num_services`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66530923",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86baad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. Codificaci√≥n de la variable objetivo (Churn: Yes/No -> 1/0)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# 3. Identificaci√≥n de variables para el ColumnTransformer\n",
    "numeric_cols = ['Tenure', 'ChargesMonthly', 'num_services']\n",
    "categorical_cols = [col for col in df.columns if col not in numeric_cols + ['Churn']]\n",
    "\n",
    "# 4. Simplificaci√≥n de valores en variables categ√≥ricas (No internet service -> No)\n",
    "\n",
    "cols_to_fix = [\n",
    "    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "    'TechSupport', 'StreamingTV', 'StreamingMovies'\n",
    "]\n",
    "\n",
    "for col in cols_to_fix:\n",
    "    df[col] = df[col].replace({'No internet service': 'No'})\n",
    "\n",
    "# El siguiente paso ser√≠a aplicar el Pipeline con OneHotEncoder y MinMaxScaler\n",
    "print(\"\\n‚úÖ Columnas redundantes eliminadas y dataset listo para encoding/scaling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff26901",
   "metadata": {},
   "source": [
    "### Estandarizaci√≥n de categor√≠as\n",
    "\n",
    "Se reemplazaron los valores \"No internet service\" por \"No\" en variables relacionadas con servicios adicionales.\n",
    "\n",
    "Esto evita crear categor√≠as artificiales al aplicar One-Hot Encoding y simplifica la interpretaci√≥n del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "\n",
    "df_numeric[\"Churn\"] = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "corr_matrix = df_numeric.corr()\n",
    "\n",
    "# Visualizar heatmap\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Matriz de Correlaci√≥n - Vari√°bles Numericas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b98112",
   "metadata": {},
   "source": [
    "### Matriz de correlaci√≥n\n",
    "\n",
    "Se analiz√≥ la correlaci√≥n entre variables num√©ricas y la variable objetivo.\n",
    "\n",
    "Este an√°lisis permite identificar:\n",
    "\n",
    "- Variables con mayor asociaci√≥n lineal con churn.\n",
    "- Posible multicolinealidad.\n",
    "- Variables con bajo poder explicativo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
